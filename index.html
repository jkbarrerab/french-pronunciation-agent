<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>French Pronunciation Trainer</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <h1>French Pronunciation Trainer</h1>
        <p class="instructions">Type a French phrase, play it to hear the correct pronunciation, then record yourself and check your pronunciation accuracy!</p>
        <input type="text" id="phrase" placeholder="Enter a French phrase">
        <div class="buttons">
            <button onclick="startRecording()">üéô Start Recording</button>
            <button onclick="stopRecording()">‚èπ Stop & Upload</button>
            <button onclick="playPhrase()">üîä Play Phrase</button>
        </div>
        <p id="result"></p>
    </div>

    <script>

        let mediaRecorder;
        let audioChunks = [];

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                mediaRecorder.start();
                console.log("Recording started...");
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    console.log("Recording stopped...");
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const wavBlob = await convertToWav(audioBlob);
                    console.log("Converted WAV Blob:", wavBlob);

                    const formData = new FormData();
                    formData.append("audio", wavBlob, "recording.wav");
                    formData.append("reference_text", document.getElementById("phrase").value);

                    console.log("Sending WAV file to backend...");
                    const response = await fetch("https://french-pronunciation-agent.onrender.com/check_pronunciation", {
                        method: "POST",
                        body: formData
                    });

                    const data = await response.json();
                    console.log("Response from server:", data);
                    document.getElementById("result").innerText = `Expected: ${data.expected}\nRecognized: ${data.recognized}\nSimilarity: ${data.similarity}%`;
                };
            }).catch(error => console.error("Microphone access error:", error));
        }

        function stopRecording() {
            if (mediaRecorder) {
                mediaRecorder.stop();
            }
        }

        function playPhrase() {
            const phrase = document.getElementById("phrase").value;
            if (!phrase) {
                alert("Please enter a phrase!");
                return;
            }
            const utterance = new SpeechSynthesisUtterance(phrase);
            utterance.lang = "fr-FR"; // Set language to French
            speechSynthesis.speak(utterance);
        }

        async function convertToWav(audioBlob) {
            const arrayBuffer = await audioBlob.arrayBuffer();
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            const offlineContext = new OfflineAudioContext(1, audioBuffer.length, 44100);
            const source = offlineContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(offlineContext.destination);
            source.start(0);

            const renderedBuffer = await offlineContext.startRendering();
            return bufferToWav(renderedBuffer);
        }

        function bufferToWav(buffer) {
            const numOfChan = buffer.numberOfChannels,
                length = buffer.length * numOfChan * 2 + 44,
                bufferArr = new ArrayBuffer(length),
                view = new DataView(bufferArr),
                channels = [],
                sampleRate = buffer.sampleRate;

            let offset = 0;
            function writeString(str) {
                for (let i = 0; i < str.length; i++) {
                    view.setUint8(offset + i, str.charCodeAt(i));
                }
                offset += str.length;
            }

            function writeInt16(value) {
                view.setInt16(offset, value, true);
                offset += 2;
            }

            writeString("RIFF");
            view.setUint32(offset, 36 + buffer.length * 2, true);
            offset += 4;
            writeString("WAVE");
            writeString("fmt ");
            view.setUint32(offset, 16, true);
            offset += 4;
            view.setUint16(offset, 1, true);
            offset += 2;
            view.setUint16(offset, numOfChan, true);
            offset += 2;
            view.setUint32(offset, sampleRate, true);
            offset += 4;
            view.setUint32(offset, sampleRate * 2 * numOfChan, true);
            offset += 4;
            view.setUint16(offset, numOfChan * 2, true);
            offset += 2;
            view.setUint16(offset, 16, true);
            offset += 2;
            writeString("data");
            view.setUint32(offset, buffer.length * 2, true);
            offset += 4;

            for (let i = 0; i < buffer.numberOfChannels; i++) {
                channels.push(buffer.getChannelData(i));
            }

            for (let i = 0; i < buffer.length; i++) {
                for (let j = 0; j < numOfChan; j++) {
                    writeInt16(channels[j][i] * 0x7FFF);
                }
            }

            return new Blob([bufferArr], { type: "audio/wav" });
        }
    </script>
</body>
</html>